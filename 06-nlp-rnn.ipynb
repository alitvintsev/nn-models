{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf990c77-afbc-4d31-85f3-b7070afdd580",
   "metadata": {},
   "source": [
    "# Text Classification with CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a411363e-ef0e-4b69-89af-0fc3a2591635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "     |████████████████████████████████| 365 kB 1.3 MB/s            \n",
      "\u001b[?25hCollecting dill<0.3.6\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 7.9 MB/s             \n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "     |████████████████████████████████| 211 kB 26.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 24.4 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 7.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.27.1)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "     |████████████████████████████████| 25.6 MB 26.3 MB/s            \n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from datasets) (4.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.63.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (945 kB)\n",
      "     |████████████████████████████████| 945 kB 68.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.19.5)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "     |████████████████████████████████| 106 kB 94.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from responses<0.19->datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm>=4.62.1->datasets) (5.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "     |████████████████████████████████| 191 kB 93.0 MB/s            \n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "     |████████████████████████████████| 270 kB 81.8 MB/s            \n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "     |████████████████████████████████| 159 kB 43.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2021.3)\n",
      "Building wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3178 sha256=785ca82465f8e6d986c07799cda909a71c9a63137355cf018c9a4d5e1fcbe5df\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built idna-ssl\n",
      "Installing collected packages: multidict, frozenlist, yarl, idna-ssl, asynctest, async-timeout, aiosignal, fsspec, filelock, dill, aiohttp, xxhash, responses, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.4.0 dill-0.3.4 filelock-3.4.1 frozenlist-1.2.0 fsspec-2022.1.0 huggingface-hub-0.4.0 idna-ssl-1.1.0 multidict-5.2.0 multiprocess-0.70.12.2 pyarrow-6.0.1 responses-0.17.0 xxhash-3.2.0 yarl-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e16168-533f-4e8b-bfa6-6da9b12bd0a1",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ded3df14-0a3c-4856-82bc-acb17415294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bde6c-98c4-4fae-bf1d-d150b11a4601",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d84e83-e4d7-4c77-bf5d-c231ad1c65a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d70da89-6670-47ef-a392-b233612b62b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0xDEAD\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a5dd1-04fb-4103-af0e-ecf06fe7879c",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d07f194-0738-428b-9357-932f5bd97047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff4fd0637c4644ab8d047694121ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853687a750d440cfb8622caacd6b9d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8402e70344bd4a239fe85ba49b782db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bf344d7ddc4bb4b86d153e1284e4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/751k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ag_news downloaded and prepared to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010953f454ac44ba9a18e744ac21fc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f4248a-d2de-44bd-99cd-6482b85368d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe46e4a-3d8a-48bb-8ea3-5d5e13b00b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f096f81-1fa4-42ac-99d3-76336de7db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a3329-0719-49ea-9794-43f47afcf459",
   "metadata": {},
   "source": [
    "### Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3ef738-d587-477e-a2b4-74ca1a02e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "wv_lst = '\\n'.join(api.info()['models'].keys())\n",
    "print(wv_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0243d2-8e9a-4cbe-8342-e8e76e1f34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c0a937b-2e69-4e9b-9428-12fa030fd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7776b3fa-4dd6-4490-9b82-a7006e591427",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "409f430f-dc2f-44a9-bfd0-75f4c1ac2bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7b0c4fc81e48a28590faa45ff546f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92130a91a69d4644b2279aca19c8f6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        'tokenized': tokenizer.tokenize(item['text'])[:MAX_LENGTH]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e5e65fc-1711-4e33-bc63-8ca304985978",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(word2vec.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd10456-d53a-4e79-be75-7bf76dd6d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    return word2idx['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38a4b0b2-555a-40f3-8ba0-61e280aa7d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662cd17e86754c32b5e6fbbb8264d147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9714257707f4cdf97d23e53eaff906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        'features': [encode(word) for word in item['tokenized']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c56a8d5b-f557-48be-85a6-fef8c04b2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['text', 'tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b77f6d15-c288-4873-918c-8329b07da436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'features'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'features'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae77e27b-7a00-4673-97fa-f72aa71150fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3661f70c-723f-4fc7-8b8c-cbf21bdb6893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(2),\n",
       " 'features': tensor([ 62980,  62980,      1,  62980,  62980,  62980,  62980,     13,  62980,\n",
       "             17,  62980,     20,  62980,     28,  62980,     28,  49286,      4,\n",
       "          62980,  62980,     48,    137, 214902,    370,   1645,     39,   8606,\n",
       "             28, 380053,      4,     70,   1321,   1745,    389,      1])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8c4eb89-5b16-4d2c-9aeb-9bdd49b974e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_len = max(len(row['features']) for row in batch)\n",
    "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long)\n",
    "    labels = torch.empty(len(batch), dtype=torch.long)\n",
    "    for idx, row in enumerate(batch):\n",
    "        to_pad = max_len - len(row['features'])\n",
    "        input_embeds[idx] = torch.cat((row['features'], torch.zeros(to_pad)))\n",
    "        labels[idx] = row['label']\n",
    "    return {'features': input_embeds, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a04b0ed-976a-4678-b095-95f15e17553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e071ca9-d410-44ab-a913-29cff7a7a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    k: DataLoader(\n",
    "        ds, shuffle=(k=='train'), batch_size=32, collate_fn=collate_fn\n",
    "    ) for k, ds in dataset.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b51c33-a558-4379-985a-ef4fa38d6d3c",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7849be5b-d549-479d-8f7d-90bf955601cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len(word2idx), embedding_dim=embed_size)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x) # (batch_size, seq_size, embed_dim)\n",
    "        x = x.permute(0, 2, 1) # (batch_size, embed_dim, seq_size)\n",
    "        x = self.cnn(x)\n",
    "        prediction = self.cl(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b06908b-58fd-4691-9ab1-05d59b700d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8af45908-bf45-418e-ac01-3e46b9ffcf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c34f38a3-fda6-437f-a374-ffed25de3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(embed_size=word2vec.vector_size, hidden_size=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0e1e80f-282f-4739-a8d0-1a36a6b9e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1900e12-69fb-4991-bfcb-41f260e67dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ca31535-ad39-477c-b017-03143d144a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c170928-7457-4d92-962a-d6d69cdde01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2):\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a91a239-997b-4567-a504-426a90e2c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.39303717017173767, accuracy: 0.8668420910835266\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, num_epochs, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b201f90-6096-4830-ab74-b3532b5e4cd2",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fdab2d0-08bc-4952-a71f-ca3b4bb180b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_h = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_x = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_x = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        '''\n",
    "        x – torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        seq_length = x.size(1)\n",
    "        for cur_idx in range(seq_length):\n",
    "            hidden = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_x + self.b_x + hidden @ self.w_h + self.b_h\n",
    "            )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "883dd5a5-cbf2-4579-ba74-f87b312ec59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.rnn = RNN(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb0953fc-fdb7-463f-9df5-776e7d86370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3afb4dc-91e3-4e58-9175-2d74f50aab07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 1.4290155172348022, accuracy: 0.2509210407733917\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ec314-c757-425d-ba83-a32bc8ccfbf8",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4985b8e-d7a7-4b70-9d93-6c652f25d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_rh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_zh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_nh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden = None):\n",
    "        '''\n",
    "        x – torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        \n",
    "        for cur_idx in range(x.size(1)):\n",
    "            r = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh\n",
    "            )\n",
    "            z = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh\n",
    "            )\n",
    "            n = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh)\n",
    "            )\n",
    "            hidden = (1 - z) * n + z * hidden\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23187516-60c7-424d-bf1e-f2643612319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.gru = GRU(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        hidden = self.gru(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c162a80-b180-48b4-adff-63bb880d509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9717e0f8-fdd9-4215-bf7d-246d11b1dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.6777563095092773, accuracy: 0.7497367858886719\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8e15f-9492-4356-a080-401d08618419",
   "metadata": {},
   "source": [
    "### GRU + Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4a6aa79-82bb-4939-801b-41d49d17daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9bfe8e2f-758a-4d6c-b92c-e7f8802d0e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5763deff-a270-4e03-a923-5342015c66c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.47792530059814453, accuracy: 0.8378946781158447\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e231c0d-b276-4fd1-b7b7-fe785587a35e",
   "metadata": {},
   "source": [
    "### Freeze Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6af40e97-fa18-4cf1-842e-d3f70022b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embed\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e376a1ba-73fb-4dca-b226-a752cfec63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
    "    freeze_embeddings(model)\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            if num_iter > num_freeze_iter and e < 1:\n",
    "                freeze_embeddings(model, True)\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf2053e3-eeae-4582-914c-0fd1f8788c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8020e141-a06d-45b3-b834-496535671192",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54129a2d-3e00-409d-a12e-8e3803f5f85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.5533571243286133, accuracy: 0.8115789294242859\n"
     ]
    }
   ],
   "source": [
    "train_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35237d94-f815-4dc4-a457-3114b499bcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
